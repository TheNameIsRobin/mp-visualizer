{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03933f9-d6c4-4bed-bd71-efff43d4e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "# Set professional styling for scientific papers\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class BenchmarkAnalyzer:\n",
    "    def __init__(self, results_file: str):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with benchmark results.\n",
    "        \n",
    "        Args:\n",
    "            results_file: Path to the JSON results file from Criterion\n",
    "        \"\"\"\n",
    "        self.data = {}\n",
    "        self.groups = set()\n",
    "        self.runtimes = set()\n",
    "        \n",
    "        # Fixed color mapping for consistency across all plots\n",
    "        self.color_map = {\n",
    "            'Native': '#2E8B57',      # Sea Green\n",
    "            'WAMR': '#FF8C00',        # Dark Orange  \n",
    "            'Wasmtime': '#87CEEB'     # Sky Blue\n",
    "        }\n",
    "        \n",
    "        # Professional styling parameters\n",
    "        self.style_params = {\n",
    "            'font.family': 'serif',\n",
    "            'font.serif': ['Times New Roman', 'DejaVu Serif'],\n",
    "            'font.size': 10,\n",
    "            'axes.labelsize': 10,\n",
    "            'axes.titlesize': 12,\n",
    "            'xtick.labelsize': 8,\n",
    "            'ytick.labelsize': 8,\n",
    "            'legend.fontsize': 8,\n",
    "            'figure.titlesize': 14,\n",
    "            'axes.linewidth': 1.2,\n",
    "            'grid.linewidth': 0.3,\n",
    "            'grid.color': '#FFFFFF',\n",
    "            'lines.linewidth': 1,\n",
    "            'axes.facecolor': '#EAEAF2',\n",
    "            'figure.facecolor': '#FFFFFF'\n",
    "        }\n",
    "        \n",
    "        plt.rcParams.update(self.style_params)\n",
    "        self._load_data(results_file)\n",
    "        \n",
    "    def _load_data(self, results_file: str):\n",
    "        \"\"\"Load and parse the JSON benchmark results.\"\"\"\n",
    "        with open(results_file, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    result = json.loads(line.strip())\n",
    "                    if result.get('reason') == 'benchmark-complete':\n",
    "                        self._process_benchmark(result)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "                    \n",
    "    def _process_benchmark(self, result: dict):\n",
    "        \"\"\"Process a single benchmark result.\"\"\"\n",
    "        benchmark_id = result['id']\n",
    "        parts = benchmark_id.split('/')\n",
    "        if len(parts) != 2:\n",
    "            return\n",
    "            \n",
    "        group, runtime = parts\n",
    "        self.groups.add(group)\n",
    "        self.runtimes.add(runtime)\n",
    "        \n",
    "        # Calculate time per iteration for each sample\n",
    "        iteration_counts = np.array(result['iteration_count'])\n",
    "        measured_values = np.array(result['measured_values'])\n",
    "        \n",
    "        # Convert from nanoseconds to microseconds for better readability\n",
    "        times_per_iteration = (measured_values / iteration_counts) / 1000\n",
    "        \n",
    "        if group not in self.data:\n",
    "            self.data[group] = {}\n",
    "        self.data[group][runtime] = times_per_iteration\n",
    "        \n",
    "    def _calculate_stats(self, data: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate statistical measures for a dataset.\"\"\"\n",
    "        # Remove outliers using IQR method\n",
    "        q75, q25 = np.percentile(data, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        lower_bound = q25 - 1.5 * iqr\n",
    "        upper_bound = q75 + 1.5 * iqr\n",
    "        clean_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean = np.mean(data)\n",
    "        median = np.median(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "        cv = (std / mean) * 100 if mean != 0 else 0\n",
    "        \n",
    "        # Confidence intervals (95%)\n",
    "        n = len(data)\n",
    "        sem = std / np.sqrt(n)\n",
    "        ci_95 = stats.t.interval(0.95, n-1, loc=mean, scale=sem)\n",
    "        \n",
    "        return {\n",
    "            'mean': mean,\n",
    "            'median': median,\n",
    "            'std': std,\n",
    "            'cv': cv,\n",
    "            'ci_95': ci_95,\n",
    "            'n_samples': len(data),\n",
    "            'n_clean': len(clean_data),\n",
    "            'raw_data': data,\n",
    "            'clean_data': clean_data\n",
    "        }\n",
    "    \n",
    "    def _filter_data(self, groups: Optional[List[str]] = None, \n",
    "                    runtimes: Optional[List[str]] = None) -> Dict:\n",
    "        \"\"\"Filter data based on specified groups and runtimes.\"\"\"\n",
    "        if groups is None:\n",
    "            groups = list(self.groups)\n",
    "        if runtimes is None:\n",
    "            runtimes = list(self.runtimes)\n",
    "            \n",
    "        filtered = {}\n",
    "        for group in groups:\n",
    "            if group in self.data:\n",
    "                filtered[group] = {}\n",
    "                for runtime in runtimes:\n",
    "                    if runtime in self.data[group]:\n",
    "                        filtered[group][runtime] = self.data[group][runtime]\n",
    "        return filtered\n",
    "    \n",
    "    def _get_runtime_color(self, runtime: str) -> str:\n",
    "        \"\"\"Get consistent color for a runtime.\"\"\"\n",
    "        return self.color_map.get(runtime, '#808080')  # Default gray for unknown runtimes\n",
    "    \n",
    "    def plot_comparison(self, groups: Optional[List[str]] = None, \n",
    "                       runtimes: Optional[List[str]] = None, \n",
    "                       log_scale: bool = False):\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "        \n",
    "        group_names = list(filtered_data.keys())\n",
    "        runtime_names = sorted(list(set().union(*[list(g.keys()) for g in filtered_data.values()])))\n",
    "        \n",
    "        x = np.arange(len(group_names))\n",
    "        bar_width = 0.2\n",
    "        spacing = 0.05\n",
    "        \n",
    "        for i, runtime in enumerate(runtime_names):\n",
    "            means = []\n",
    "            errors = []\n",
    "            for group in group_names:\n",
    "                if runtime in filtered_data[group]:\n",
    "                    stats = self._calculate_stats(filtered_data[group][runtime])\n",
    "                    means.append(stats['mean'])\n",
    "                    errors.append(stats['std'] / np.sqrt(stats['n_clean']))\n",
    "                else:\n",
    "                    means.append(0)\n",
    "                    errors.append(0)\n",
    "            \n",
    "            offset = (i - len(runtime_names)/2 + 0.5) * (bar_width + spacing)\n",
    "            bars = ax.bar(x + offset, means, bar_width, label=runtime, \n",
    "                         color=self._get_runtime_color(runtime), alpha=0.8, \n",
    "                         yerr=errors, capsize=4, error_kw={'linewidth': 1.5},\n",
    "                         edgecolor='black', linewidth=1.2)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, mean_val in zip(bars, means):\n",
    "                if mean_val > 0:\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height + height*0.02,\n",
    "                           f'{mean_val:.1f}', ha='center', va='bottom', \n",
    "                           fontsize=9, fontweight='bold')\n",
    "                    \n",
    "        # Add group seperator\n",
    "        group_width = len(runtime_names) * (bar_width + spacing) - spacing\n",
    "        group_left = x - group_width/2\n",
    "        group_right = x + group_width/2\n",
    "        for i, group_x in enumerate(x):\n",
    "            ax.axvspan(group_left[i], group_right[i], \n",
    "                       facecolor='#DFDFE6', alpha=0.3, zorder=0)\n",
    "            \n",
    "        ax.set_xlabel('Benchmark Groups', fontweight='bold')\n",
    "        ax.set_ylabel('Execution Time (Î¼s)', fontweight='bold')\n",
    "        ax.set_title('Performance Comparison Across Runtime Environments', fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(group_names)\n",
    "        \n",
    "        # Legend styling\n",
    "        legend = ax.legend(frameon=True, fancybox=False, shadow=False, \n",
    "                          borderpad=1, columnspacing=1.5)\n",
    "        legend.get_frame().set_facecolor('white')\n",
    "        legend.get_frame().set_alpha(0.9)\n",
    "        \n",
    "        if log_scale:\n",
    "            ax.set_yscale('log')\n",
    "        else:\n",
    "            # Add padding at top for labels\n",
    "            ylim_top = ax.get_ylim()[1]\n",
    "            ax.set_ylim(top=ylim_top * 1.15)\n",
    "        \n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"comp_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_relative(self, groups: Optional[List[str]] = None, \n",
    "                     runtimes: Optional[List[str]] = None, \n",
    "                     log_scale: bool = False):\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "        \n",
    "        group_names = list(filtered_data.keys())\n",
    "        runtime_names = sorted(list(set().union(*[list(g.keys()) for g in filtered_data.values()])))\n",
    "        \n",
    "        x = np.arange(len(group_names))\n",
    "        bar_width = 0.20\n",
    "        spacing = 0.05\n",
    "        \n",
    "        for i, runtime in enumerate(runtime_names):\n",
    "            execution_times = []\n",
    "            relative_labels = []\n",
    "            \n",
    "            for group in group_names:\n",
    "                if runtime in filtered_data[group]:\n",
    "                    # Calculate means for all runtimes in this group\n",
    "                    group_means = {}\n",
    "                    for rt in filtered_data[group]:\n",
    "                        stats = self._calculate_stats(filtered_data[group][rt])\n",
    "                        group_means[rt] = stats['mean']\n",
    "                    \n",
    "                    fastest = min(group_means.values())\n",
    "                    current = group_means[runtime]\n",
    "                    relative = current / fastest\n",
    "                    \n",
    "                    execution_times.append(current)\n",
    "                    relative_labels.append(relative)\n",
    "                else:\n",
    "                    execution_times.append(0)\n",
    "                    relative_labels.append(0)\n",
    "            \n",
    "            offset = (i - len(runtime_names)/2 + 0.5) * (bar_width + spacing)\n",
    "            bars = ax.bar(x + offset, execution_times, bar_width, label=runtime, \n",
    "                         color=self._get_runtime_color(runtime), alpha=0.8,\n",
    "                         edgecolor='black', linewidth=1.2)\n",
    "            \n",
    "            # Add relative performance labels on bars\n",
    "            for j, (bar, rel_val) in enumerate(zip(bars, relative_labels)):\n",
    "                if rel_val > 0:\n",
    "                    height = bar.get_height()\n",
    "                    if rel_val == 1.0:\n",
    "                        label_text = \"1.0000Ã—\\n(fastest)\"\n",
    "                    else:\n",
    "                        label_text = f\"{rel_val:.4f}Ã—\\nslower\"\n",
    "                    \n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height + height*0.02,\n",
    "                           label_text, ha='center', va='bottom', fontsize=9,\n",
    "                           fontweight='bold')\n",
    "                    \n",
    "        # Add group seperator\n",
    "        group_width = len(runtime_names) * (bar_width + spacing) - spacing\n",
    "        group_left = x - group_width/2\n",
    "        group_right = x + group_width/2\n",
    "        for i, group_x in enumerate(x):\n",
    "            ax.axvspan(group_left[i], group_right[i], \n",
    "                       facecolor='#DFDFE6', alpha=0.3, zorder=0)\n",
    "        \n",
    "        ax.set_xlabel('Benchmark Groups', fontweight='bold')\n",
    "        ax.set_ylabel('Execution Time (Î¼s)', fontweight='bold')\n",
    "        ax.set_title('Relative Performance Analysis\\n(Labels show slowdown factor vs. fastest)', \n",
    "                    fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(group_names)\n",
    "        \n",
    "        # Legend styling\n",
    "        legend = ax.legend(frameon=True, fancybox=False, shadow=False, \n",
    "                          borderpad=1, columnspacing=1.5)\n",
    "        legend.get_frame().set_facecolor('white')\n",
    "        legend.get_frame().set_alpha(0.9)\n",
    "        \n",
    "        if log_scale:\n",
    "            ax.set_yscale('log')\n",
    "        else:\n",
    "            # Add some padding at the top for labels\n",
    "            ylim_top = ax.get_ylim()[1]\n",
    "            ax.set_ylim(top=ylim_top * 1.3)\n",
    "        \n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"rel_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_stability(self, groups: Optional[List[str]] = None, \n",
    "                      runtimes: Optional[List[str]] = None):\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "        \n",
    "        group_names = list(filtered_data.keys())\n",
    "        runtime_names = sorted(list(set().union(*[list(g.keys()) for g in filtered_data.values()])))\n",
    "        \n",
    "        x = np.arange(len(group_names))\n",
    "        bar_width = 0.20\n",
    "        spacing = 0.05\n",
    "        \n",
    "        for i, runtime in enumerate(runtime_names):\n",
    "            cvs = []\n",
    "            for group in group_names:\n",
    "                if runtime in filtered_data[group]:\n",
    "                    stats = self._calculate_stats(filtered_data[group][runtime])\n",
    "                    cvs.append(stats['cv'])\n",
    "                else:\n",
    "                    cvs.append(0)\n",
    "            \n",
    "            offset = (i - len(runtime_names)/2 + 0.5) * (bar_width + spacing)\n",
    "            bars = ax.bar(x + offset, cvs, bar_width, label=runtime, \n",
    "                         color=self._get_runtime_color(runtime), alpha=0.8,\n",
    "                         edgecolor='black', linewidth=1.2)\n",
    "            \n",
    "            # Add CV values on bars\n",
    "            for bar, cv_val in zip(bars, cvs):\n",
    "                if cv_val > 0:\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height + height*0.02,\n",
    "                           f'{cv_val:.4f}%', ha='center', va='bottom', \n",
    "                           fontsize=9, fontweight='bold')\n",
    "                    \n",
    "        # Add group seperator\n",
    "        group_width = len(runtime_names) * (bar_width + spacing) - spacing\n",
    "        group_left = x - group_width/2\n",
    "        group_right = x + group_width/2\n",
    "        for i, group_x in enumerate(x):\n",
    "            ax.axvspan(group_left[i], group_right[i], \n",
    "                       facecolor='#DFDFE6', alpha=0.3, zorder=0)\n",
    "        \n",
    "        ax.set_xlabel('Benchmark Groups', fontweight='bold')\n",
    "        ax.set_ylabel('Coefficient of Variation (%)', fontweight='bold')\n",
    "        ax.set_title('Performance Stability Analysis\\n(Lower values indicate more stable performance)', \n",
    "                    fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(group_names)\n",
    "        \n",
    "        # Legend styling\n",
    "        legend = ax.legend(frameon=True, fancybox=False, shadow=False, \n",
    "                          borderpad=1, columnspacing=1.5)\n",
    "        legend.get_frame().set_facecolor('white')\n",
    "        legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "        # Add padding at top for labels\n",
    "        ylim_top = ax.get_ylim()[1]\n",
    "        ax.set_ylim(top=ylim_top * 1.15)\n",
    "        \n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"stab_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def print_summary(self, groups: Optional[List[str]] = None, \n",
    "                     runtimes: Optional[List[str]] = None):\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"BENCHMARK ANALYSIS SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for group in filtered_data:\n",
    "            print(f\"\\nðŸ“Š GROUP: {group}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for runtime in sorted(filtered_data[group].keys()):\n",
    "                stats = self._calculate_stats(filtered_data[group][runtime])\n",
    "                \n",
    "                print(f\"\\nðŸš€ Runtime: {runtime}\")\n",
    "                print(f\"  â€¢ Mean:         {stats['mean']:.4f} Î¼s\")\n",
    "                print(f\"  â€¢ Median:       {stats['median']:.4f} Î¼s\")\n",
    "                print(f\"  â€¢ Std Dev:      {(stats['std']*1000):.4f} ns\")\n",
    "                print(f\"  â€¢ CV:           {stats['cv']:.4f}%\")\n",
    "                print(f\"  â€¢ 95% CI:       [{stats['ci_95'][0]:.4f}, {stats['ci_95'][1]:.4f}] Î¼s\")\n",
    "                print(f\"  â€¢ Samples:      {stats['n_clean']}/{stats['n_samples']} (after outlier removal)\")\n",
    "    \n",
    "    def plot_boxes(self, groups: Optional[List[str]] = None, \n",
    "                   runtimes: Optional[List[str]] = None):\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, len(filtered_data), figsize=(5*len(filtered_data), 6), dpi=300)\n",
    "        if len(filtered_data) == 1:\n",
    "            axes = [axes]\n",
    "        group_names = set()\n",
    "        runtime_names = set()\n",
    "        for idx, (group, group_data) in enumerate(filtered_data.items()):\n",
    "            group_names.add(group)\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            data_for_box = []\n",
    "            tick_labels = []\n",
    "            colors = []\n",
    "            \n",
    "            for runtime in sorted(group_data.keys()):\n",
    "                runtime_names.add(runtime)\n",
    "                stats = self._calculate_stats(group_data[runtime])\n",
    "                data_for_box.append(stats['raw_data'])\n",
    "                tick_labels.append(runtime)\n",
    "                colors.append(self._get_runtime_color(runtime))\n",
    "            \n",
    "            bp = ax.boxplot(data_for_box, tick_labels=tick_labels, patch_artist=True,\n",
    "                           boxprops=dict(linewidth=1.5),\n",
    "                           whiskerprops=dict(linewidth=1.5),\n",
    "                           capprops=dict(linewidth=1.5),\n",
    "                           medianprops=dict(linewidth=2, color='red'))\n",
    "            \n",
    "            # Color the boxes\n",
    "            for patch, color in zip(bp['boxes'], colors):\n",
    "                patch.set_facecolor(color)\n",
    "                patch.set_alpha(0.7)\n",
    "            \n",
    "            ax.set_title(f'{group}', fontweight='bold', pad=15)\n",
    "            ax.set_ylabel('Time per Iteration (Î¼s)', fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "        \n",
    "        plt.suptitle('Distribution Analysis via Box Plots', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"box_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_evolution(self, groups: Optional[List[str]] = None, \n",
    "                      runtimes: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Create line plots showing evolution of execution time across samples.\n",
    "        \"\"\"\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        fig, axes = plt.subplots(len(filtered_data), 1, figsize=(12, 5*len(filtered_data)), dpi=300)\n",
    "        if len(filtered_data) == 1:\n",
    "            axes = [axes]\n",
    "        group_names = set()\n",
    "        runtime_names = set()\n",
    "        for idx, (group, group_data) in enumerate(filtered_data.items()):\n",
    "            group_names.add(group)\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            for runtime in sorted(group_data.keys()):\n",
    "                runtime_names.add(runtime)\n",
    "                data = group_data[runtime]\n",
    "                ax.plot(range(len(data)), data, label=runtime, \n",
    "                       color=self._get_runtime_color(runtime), alpha=0.8, \n",
    "                       linewidth=2, marker='o', markersize=3, markevery=max(1, len(data)//50))\n",
    "            \n",
    "            ax.set_title(f'{group} - Sample Evolution', fontweight='bold', pad=15)\n",
    "            ax.set_xlabel('Sample Index', fontweight='bold')\n",
    "            ax.set_ylabel('Time per Iteration (Î¼s)', fontweight='bold')\n",
    "            \n",
    "            # Legend styling\n",
    "            legend = ax.legend(frameon=True, fancybox=False, shadow=False)\n",
    "            legend.get_frame().set_facecolor('white')\n",
    "            legend.get_frame().set_alpha(0.9)\n",
    "            \n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "        plt.suptitle('Performance Evolution Across Samples', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"evol_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_distribution_flip(self, groups: Optional[List[str]] = None, \n",
    "                         runtimes: Optional[List[str]] = None):\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        n_groups = len(filtered_data)\n",
    "        n_runtimes = max(len(group_data) for group_data in filtered_data.values())\n",
    "        \n",
    "        fig, axes = plt.subplots(n_groups, n_runtimes, \n",
    "                                figsize=(5*n_runtimes, 4*n_groups), dpi=300)\n",
    "        if n_groups == 1 and n_runtimes == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif n_groups == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        elif n_runtimes == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        group_names = set()\n",
    "        runtime_names = set()\n",
    "        for group_idx, (group, group_data) in enumerate(filtered_data.items()):\n",
    "            group_names.add(group)\n",
    "            for runtime_idx, runtime in enumerate(sorted(group_data.keys())):\n",
    "                runtime_names.add(runtime)\n",
    "                ax = axes[group_idx, runtime_idx]\n",
    "                \n",
    "                stats = self._calculate_stats(group_data[runtime])\n",
    "                data = stats['raw_data']\n",
    "                \n",
    "                # Create density estimate\n",
    "                from scipy.stats import gaussian_kde\n",
    "                kde = gaussian_kde(data)\n",
    "                \n",
    "                # Create smooth x values for the curve\n",
    "                x_min, x_max = data.min(), data.max()\n",
    "                x_range = x_max - x_min\n",
    "                x_smooth = np.linspace(x_min - 0.1*x_range, x_max + 0.1*x_range, 300)\n",
    "                density = kde(x_smooth)\n",
    "                \n",
    "                # Create area plot\n",
    "                ax.fill_between(x_smooth, 0, density, alpha=0.6, \n",
    "                               color=self._get_runtime_color(runtime), \n",
    "                               label=f'{runtime} Distribution')\n",
    "                ax.plot(x_smooth, density, color=self._get_runtime_color(runtime), \n",
    "                       linewidth=2)\n",
    "                \n",
    "                # Add mean line\n",
    "                ax.axvline(stats['mean'], color='red', linestyle='--', linewidth=2, \n",
    "                          label=f\"Mean: {stats['mean']:.4f} Î¼s\")\n",
    "                \n",
    "                # Add 95% CI shading\n",
    "                ci_mask = (x_smooth >= stats['ci_95'][0]) & (x_smooth <= stats['ci_95'][1])\n",
    "                ax.fill_between(x_smooth, 0, density, where=ci_mask, alpha=0.8, \n",
    "                               color='#ffb3ba', label='95% CI')\n",
    "                \n",
    "                ax.set_title(f'{group} - {runtime}', fontweight='bold', pad=10)\n",
    "                ax.set_xlabel('Time per Iteration (Î¼s)', fontweight='bold')\n",
    "                ax.set_ylabel('Probability Density', fontweight='bold')\n",
    "                \n",
    "                # Legend styling\n",
    "                legend = ax.legend(frameon=True, fancybox=False, shadow=False, fontsize=9)\n",
    "                legend.get_frame().set_facecolor('white')\n",
    "                legend.get_frame().set_alpha(0.9)\n",
    "                \n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for group_idx in range(n_groups):\n",
    "            for runtime_idx in range(len(sorted(filtered_data[list(filtered_data.keys())[group_idx]].keys())), n_runtimes):\n",
    "                if n_runtimes > 1:\n",
    "                    axes[group_idx, runtime_idx].set_visible(False)\n",
    "        \n",
    "        plt.suptitle('Performance Distribution Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"dist_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_distribution(self, groups: Optional[List[str]] = None, \n",
    "                         runtimes: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Create area plots showing distribution with 95% confidence intervals.\n",
    "        \"\"\"\n",
    "        filtered_data = self._filter_data(groups, runtimes)\n",
    "        \n",
    "        n_groups = len(filtered_data)\n",
    "        n_runtimes = max(len(group_data) for group_data in filtered_data.values())\n",
    "        \n",
    "        fig, axes = plt.subplots(n_runtimes, n_groups, \n",
    "                                figsize=(5*n_groups, 4*n_runtimes), dpi=300)\n",
    "        if n_groups == 1 and n_runtimes == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif n_runtimes == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        elif n_groups == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        group_names = set()\n",
    "        runtime_names = set()\n",
    "        for group_idx, (group, group_data) in enumerate(filtered_data.items()):\n",
    "            group_names.add(group)\n",
    "            for runtime_idx, runtime in enumerate(sorted(group_data.keys())):\n",
    "                runtime_names.add(runtime)\n",
    "                ax = axes[runtime_idx, group_idx]\n",
    "                \n",
    "                stats = self._calculate_stats(group_data[runtime])\n",
    "                data = stats['raw_data']\n",
    "                \n",
    "                # Create density estimate\n",
    "                from scipy.stats import gaussian_kde\n",
    "                kde = gaussian_kde(data)\n",
    "                \n",
    "                # Create smooth x values for the curve\n",
    "                x_min, x_max = data.min(), data.max()\n",
    "                x_range = x_max - x_min\n",
    "                x_smooth = np.linspace(x_min - 0.1*x_range, x_max + 0.1*x_range, 300)\n",
    "                density = kde(x_smooth)\n",
    "                \n",
    "                # Create area plot\n",
    "                ax.fill_between(x_smooth, 0, density, alpha=0.6, \n",
    "                               color=self._get_runtime_color(runtime), \n",
    "                               label=f'{runtime} Distribution')\n",
    "                ax.plot(x_smooth, density, color=self._get_runtime_color(runtime), \n",
    "                       linewidth=2)\n",
    "                \n",
    "                # Add mean line\n",
    "                ax.axvline(stats['mean'], color='red', linestyle='--', linewidth=2, \n",
    "                          label=f\"Mean: {stats['mean']:.4f} Î¼s\")\n",
    "                \n",
    "                # Add 95% CI shading\n",
    "                ci_mask = (x_smooth >= stats['ci_95'][0]) & (x_smooth <= stats['ci_95'][1])\n",
    "                ax.fill_between(x_smooth, 0, density, where=ci_mask, alpha=0.8, \n",
    "                               color='#ffb3ba', label='95% CI')\n",
    "                \n",
    "                ax.set_title(f'{group} - {runtime}', fontweight='bold', pad=10)\n",
    "                ax.set_xlabel('Time per Iteration (Î¼s)', fontweight='bold')\n",
    "                ax.set_ylabel('Probability Density', fontweight='bold')\n",
    "                \n",
    "                # Legend styling\n",
    "                legend = ax.legend(frameon=True, fancybox=False, shadow=False, fontsize=9)\n",
    "                legend.get_frame().set_facecolor('white')\n",
    "                legend.get_frame().set_alpha(0.9)\n",
    "                \n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for group_idx in range(n_groups):\n",
    "            for runtime_idx in range(len(sorted(filtered_data[list(filtered_data.keys())[group_idx]].keys())), n_runtimes):\n",
    "                if n_runtimes > 1:\n",
    "                    axes[runtime_idx, group_idx].set_visible(False)\n",
    "        \n",
    "        plt.suptitle('Performance Distribution Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"my_new_results\") / f\"dist_{'_'.join(group_names)}_{'_'.join(runtime_names)}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2895782b-bca0-4cb7-b0f9-ddb68c60e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = BenchmarkAnalyzer('results.log')\n",
    "groups = [\"Runtime Setup\", \"Cold Ping Pong Execution\", \"Hot Ping Pong Execution\"]\n",
    "runtimes = [\"Native\", \"WAMR\", \"Wasmtime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59705deb-fb8c-4065-adc8-9c44ed294ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š GROUP: Cold Ping Pong Execution\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Runtime: Native\n",
      "  â€¢ Mean:         594.5275 Î¼s\n",
      "  â€¢ Median:       594.5636 Î¼s\n",
      "  â€¢ Std Dev:      281.8579 ns\n",
      "  â€¢ CV:           0.0474%\n",
      "  â€¢ 95% CI:       [594.4715, 594.5834] Î¼s\n",
      "  â€¢ Samples:      99/100 (after outlier removal)\n",
      "\n",
      "ðŸš€ Runtime: WAMR\n",
      "  â€¢ Mean:         1211.0415 Î¼s\n",
      "  â€¢ Median:       1210.9849 Î¼s\n",
      "  â€¢ Std Dev:      5144.4222 ns\n",
      "  â€¢ CV:           0.4248%\n",
      "  â€¢ 95% CI:       [1210.0207, 1212.0622] Î¼s\n",
      "  â€¢ Samples:      100/100 (after outlier removal)\n",
      "\n",
      "ðŸš€ Runtime: Wasmtime\n",
      "  â€¢ Mean:         1301.8975 Î¼s\n",
      "  â€¢ Median:       1300.5868 Î¼s\n",
      "  â€¢ Std Dev:      4895.5251 ns\n",
      "  â€¢ CV:           0.3760%\n",
      "  â€¢ 95% CI:       [1300.9262, 1302.8689] Î¼s\n",
      "  â€¢ Samples:      86/100 (after outlier removal)\n",
      "\n",
      "ðŸ“Š GROUP: Hot Ping Pong Execution\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Runtime: Native\n",
      "  â€¢ Mean:         589.0368 Î¼s\n",
      "  â€¢ Median:       589.0307 Î¼s\n",
      "  â€¢ Std Dev:      69.9196 ns\n",
      "  â€¢ CV:           0.0119%\n",
      "  â€¢ 95% CI:       [589.0230, 589.0507] Î¼s\n",
      "  â€¢ Samples:      98/100 (after outlier removal)\n",
      "\n",
      "ðŸš€ Runtime: WAMR\n",
      "  â€¢ Mean:         1185.4778 Î¼s\n",
      "  â€¢ Median:       1185.8310 Î¼s\n",
      "  â€¢ Std Dev:      673.0608 ns\n",
      "  â€¢ CV:           0.0568%\n",
      "  â€¢ 95% CI:       [1185.3442, 1185.6113] Î¼s\n",
      "  â€¢ Samples:      76/100 (after outlier removal)\n",
      "\n",
      "ðŸš€ Runtime: Wasmtime\n",
      "  â€¢ Mean:         1184.4430 Î¼s\n",
      "  â€¢ Median:       1184.2941 Î¼s\n",
      "  â€¢ Std Dev:      522.5048 ns\n",
      "  â€¢ CV:           0.0441%\n",
      "  â€¢ 95% CI:       [1184.3393, 1184.5467] Î¼s\n",
      "  â€¢ Samples:      89/100 (after outlier removal)\n",
      "\n",
      "ðŸ“Š GROUP: Runtime Setup\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Runtime: Native\n",
      "  â€¢ Mean:         1.9466 Î¼s\n",
      "  â€¢ Median:       1.9483 Î¼s\n",
      "  â€¢ Std Dev:      10.5846 ns\n",
      "  â€¢ CV:           0.5438%\n",
      "  â€¢ 95% CI:       [1.9445, 1.9487] Î¼s\n",
      "  â€¢ Samples:      93/100 (after outlier removal)\n",
      "\n",
      "ðŸš€ Runtime: WAMR\n",
      "  â€¢ Mean:         253.1126 Î¼s\n",
      "  â€¢ Median:       253.1301 Î¼s\n",
      "  â€¢ Std Dev:      258.4145 ns\n",
      "  â€¢ CV:           0.1021%\n",
      "  â€¢ 95% CI:       [253.0613, 253.1638] Î¼s\n",
      "  â€¢ Samples:      96/100 (after outlier removal)\n",
      "\n",
      "ðŸš€ Runtime: Wasmtime\n",
      "  â€¢ Mean:         19559.1592 Î¼s\n",
      "  â€¢ Median:       19559.8473 Î¼s\n",
      "  â€¢ Std Dev:      11656.5225 ns\n",
      "  â€¢ CV:           0.0596%\n",
      "  â€¢ 95% CI:       [19556.8463, 19561.4721] Î¼s\n",
      "  â€¢ Samples:      98/100 (after outlier removal)\n"
     ]
    }
   ],
   "source": [
    "analyzer.print_summary()\n",
    "# analyzer.plot_comparison(groups=groups[1:], runtimes=runtimes[:], log_scale=False)\n",
    "\n",
    "# analyzer.plot_relative(groups=groups[2:3], runtimes=runtimes[:], log_scale=False)\n",
    "\n",
    "# analyzer.plot_distribution(groups=groups[2:3], runtimes=runtimes[1:])\n",
    "# analyzer.plot_distribution_flip(groups=groups[2:3], runtimes=runtimes[1:])\n",
    "\n",
    "# analyzer.plot_stability(groups=groups[:], runtimes=runtimes[:])\n",
    "\n",
    "# analyzer.plot_boxes()\n",
    "\n",
    "# analyzer.plot_boxes(groups=groups[2:3], runtimes=runtimes[1:])\n",
    "# analyzer.plot_boxes(groups=groups[0:1], runtimes=runtimes[1:2])\n",
    "# analyzer.plot_boxes(groups=groups[0:1], runtimes=runtimes[2:3])\n",
    "# analyzer.plot_boxes(groups=groups[1:2], runtimes=runtimes[0:1])\n",
    "# analyzer.plot_boxes(groups=groups[1:2], runtimes=runtimes[1:2])\n",
    "# analyzer.plot_boxes(groups=groups[1:2], runtimes=runtimes[2:3])\n",
    "# analyzer.plot_boxes(groups=groups[2:3], runtimes=runtimes[0:1])\n",
    "# analyzer.plot_boxes(groups=groups[2:3], runtimes=runtimes[1:2])\n",
    "# analyzer.plot_boxes(groups=groups[2:3], runtimes=runtimes[2:3])\n",
    "\n",
    "# analyzer.plot_evolution(groups=groups[:], runtimes=runtimes[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a7662-c4d1-4de3-b1ac-4e3c62bacd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MP Visualizer",
   "language": "python",
   "name": "mp-visualizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
